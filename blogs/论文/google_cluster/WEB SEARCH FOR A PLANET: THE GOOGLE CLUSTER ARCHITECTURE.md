## 谷歌集群架构

很少有Web服务像搜索引擎那样需要对每个请求进行大量的计算。平均一个请求需要读取数百兆字节数据，并消耗数百亿个CPU周期。要支持每秒数千个查询的高峰请求流，就需要一个与大型超级计算机安装规模相当的基础架构。将超过15,000台商用级PC与容错软件相结合，所创建的解决方案比采用少量高端服务器构建的同类系统更具成本效益

在这里，我们介绍了Google集群的体系结构，并讨论了影响其设计的最重要因素：能源效率和性价比。

我们的应用程序提供了简单的并行化：不同的查询可以在不同的处理器上运行，并且总索引已分区，因此单个查询可以使用多个处理器。因此，处理器的性价比会比峰值处理性能更重要。

## Google架构概述

Google的软件架构来自两个基础。首先，Google提供软件级而不是服务器级硬件的可靠性，因此可以使用商用PC以低端价格构建高端计算集群。其次，由于可以通过并行处理单个请求来应对服务器响应时间，我们针对最佳聚合请求吞吐量而不是峰值服务器响应时间进行设计

我们认为，从不可靠的商用PC集群中构建可靠的计算基础架构能够为应用程序提供最佳的性价比。通过在许多不同的机器上复制服务并自动检测和处理故障，我们在软件级别的环境中提供了可靠性。这种基于软件的可靠性涵盖许多不同领域，涉及我们系统设计的所有部分

### Google查询服务

当用户向Google输入查询（例如www.google.com/search?q=ieee+society）时，用户的浏览器会首先执行域名系统（DNS）查找，以将www.google.com映射到特定的IP地址。为了提供足够的容量来处理查询流量，我们的服务由遍布全球的多个集群组成。每个集群大约有数千台计算机，而且地理分布的设置可以保护我们免受灾难性的数据中心故障（例如由于地震和大规模电源故障引起的故障）的影响。基于DNS的负载平衡系统通过考虑用户与每个物理群集的地理位置相近来选择群集。负载平衡系统可最大程度地缩短用户请求的往返时间，同时还考虑了各个群集的可用容量。

然后，用户的浏览器向这些集群之一发送超文本传输协议（HTTP）请求，此后，对该查询的处理完全在该集群本地进行。每个集群中基于硬件的负载平衡器监视可用的Google Web服务器（GWS）集合，并对其中的一组请求执行本地负载平衡。收到查询后，GWS机器会协调查询执行并将结果格式化为对用户浏览器的超文本标记语言（HTML）响应。 图1说明了这些步骤。查询执行包括两个主要阶段。在第一阶段，索引服务器查询反向索引，该索引将每个查询词映射到匹配的文档列表（命中列表）。索引服务器然后通过与各个查询词的命中列表相交来确定一组相关文档，并且它们为每个文档计算相关性得分。此相关性分数决定了输出页面上结果的顺序。

由于数据量大，搜索过程具有挑战性：原始文档包含数十TB的未压缩数据，并且由该原始数据产生的反向索引本身就是许多TB的数据。幸运的是，通过将索引分为多个部分（索引分片），搜索可以高度并行化，每个部分都具有从完整索引中随机选择的文档子集。如果某个分片的副本出现故障，负载均衡器将避免使用它进行查询，并且我们的集群管理系统的其他组件将尝试恢复该副本或最终将其替换为另一台计算机。

查询执行的第一阶段的最终结果是文档标识符（docid）的有序列表。第二阶段涉及获取此docid列表，并计算这些文档的实际标题和统一资源定位符，以及特定于查询的文档摘要。文档服务器（文档服务器）处理此工作，从磁盘上获取每个文档以提取标题和上下文关键字摘要。与索引查找阶段一样，策略是通过以下方式划分所有文档的处理：
1:随机将文档分发到较小的碎片中
2:有多个服务器副本负责处理每个分片
3: 通过负载均衡器路由请求
文档服务器群集必须有权访问整个Web的联机低延迟副本。实际上，由于副本的性能和可用性需求，因此Google在其群集中存储了数十个Web副本。除了建立索引和提供文件的阶段外，GWS还会在收到查询后启动其他一些辅助任务，例如将查询发送到拼写检查系统和广告服务系统以生成相关广告。完成所有阶段后，GWS会为输出页面生成适当的HTML，并将其返回给用户的浏览器。

### 使用副本实现可用性和容错

我们已经对系统进行了结构设计，以便大多数访问索引和其他与查询相关的数据结构都是只读的：更新相对不频繁，并且我们通常可以通过在更新过程中将查询从服务副本中转移来安全地执行它们。该原则回避了在使用通用数据库时通常会出现的许多一致性问题。

我们还积极地利用了应用程序中非常大量的固有并行性：例如，我们将大索引中匹配文档的查找转换为许多较小索引中的匹配文档查找，然后进行了合并。同样，我们将查询流分为多个流，每个流由一个集群处理。在每个池中添加计算机可增加服务容量，而添加分片可适应索引的增长。通过在许多机器上进行并行搜索，我们减少了响应查询所需的平均等待时间，将总计算量分配给了更多的CPU和磁盘。由于各个分片无需相互通信，因此加速几乎是线性的。换句话说，各个索引服务器的CPU速度不会直接影响搜索的整体性能，因为我们可以增加分片的数量以适应速度较慢的CPU，反之亦然。因此，我们的硬件选择过程侧重于为我们的应用程序提供出色请求吞吐量的计算机，而不是提供最高单线程性能的计算机。

总而言之，Google集群遵循以下三个主要设计原则：

软件可靠性：从软件层面容忍故障，而不是从硬件层面去解决

使用多副本以获得更好的请求吞吐量和可用性：由于机器本质上是不可靠的，因此我们在许多机器上复制了每个内部服务。因为我们已经跨多台机器复制了服务以获得足够的容量，所以这种容错几乎是免费的。

价格/性能优于峰值性能：我们购买的是当前性价比最高的CPU，而不是性能最好的CPU。

使用商用PC可以降低计算成本： 结果，我们可以负担每个查询使用更多的计算资源，在我们的排名算法中使用更昂贵的技术，或者搜索更大的文档索引。

## 利用商品零件

Google的机架由40到80个基于x86的服务器组成，这些服务器安装在定制机架的两侧（机架的每一侧包含20个20u或40u 服务器）。已有几代CPU投入使用，从单处理器533 MHz基于Intel-Celeron的服务器到双1.4 GHz Intel Pentium III服务器。索引服务器通常比文档服务器具有更少的磁盘空间，因为前者的CPU工作量更大。机架两侧的服务器通过100 Mbps以太网交换机互连，该交换机具有一个或两个千兆位上行链路，以及一个将所有机架连接在一起的核心千兆位交换机。

我们的最终选择标准是每次查询的成本，表示为资本支出（折旧）和运营成本（托管，系统管理和维修）之和除以性能。实际上，由于与新机器相比性能方面的差异，服务器的使用寿命不会超过两到三年。三年以上的计算机比当前的计算机要慢得多，因此很难在包含这两种类型的集群中实现正确的负载分配和配置。由于折旧期相对较短，因此设备成本在总体成本中占主要地位。

由于Google服务器是定制服务器，因此我们将使用价格信息来比较基于PC的服务器机架。例如，在2002年末，在RackSaver.com上提供了一架88台双CPU 2 GHz Intel Xeon服务器的机架，这些服务器具有2 GB的内存和80 GB的硬盘，价格约为278,000美元。这个数字意味着三年内每个机架每月的资本成本为$ 7,700。人员和托管费用刨除在外。

成本的相对重要性使传统服务器解决方案对我们的吸引力较小，因为它们提高了性能但降低了性价比。同样，尽管SCSI磁盘更快，更可靠，但它们的成本通常是同容量IDE驱动器的两倍或三倍。

对于像我们这样的高度可并行化的应用程序而言，使用廉价的基于PC的群集的成本优势可能非常可观。$ 278,000的示例机架包含176个2 GHz Xeon CPU，176 Gb RAM和7 TB磁盘空间。相比之下，典型的基于x86的服务器包含八个2-GHz Xeon CPU，64 GB的RAM和8 TB的磁盘空间。 它的成本约为758,000美元。换句话说，多处理器服务器的价格高出三倍左右，但CPU数量减少了22倍，RAM减少了三倍，磁盘空间也略多。

操作数千台中型PC而不是几台高端多处理器服务器会导致大量的系统管理和维修成本。但是，对于像Google这样相对同质的应用程序，其中大多数服务器都运行极少数应用程序之一，因此这些成本是可以控制的。假设可以使用在计算机组上安装和升级软件的工具，则维护1000台服务器的时间和成本不会比维护100台服务器的成本高很多，因为所有计算机都具有相同的配置。同样，使用可伸缩应用程序监视系统监视群集的成本不会随群集大小的增加而大大增加。此外，我们可以通过分批进行维修，并确保可以轻松更换掉故障率最高的组件（例如磁盘和电源），从而将维修成本保持在合理的较低水平。

## 电源问题

功耗和散热问题是一个有挑战性的问题。具有双1.4 GHz Pentium III处理器的中档服务器在负载下可吸收约90 W的直流功率：两个CPU约55 W，磁盘驱动器约10 W，而DRAM和主板则为25W。ATX电源的典型效率约为75％，这意味着每台服务器的交流电源功率为120瓦，或者每个机架约为10千瓦。机架比较适合25平方英尺的空间，因此功率密度为400 W / ft2。使用高端处理器，机架的功率密度可以超过700 W / ft2。不幸的是，商业数据中心的典型功率密度在70至150 W / ft2之间，远低于PC群集所需的功率密度。因此，即使使用相对简单的包装的低技术PC集群也需要特殊的冷却或额外的空间，以将功率密度降低到典型数据中心所能承受的水平。

功率降低的服务器对于大型集群很有吸引力，但是您必须牢记一些注意事项。首先，降低功率是可取的，但是对于我们的应用程序来说，必须降低功率，而不会相应降低性能：计算的是单位性能的瓦数，而不是单独的瓦数。其次，第二,低功耗服务器不能更昂贵，因为折旧的费用通常超过电源成本。前面提到的10 kW机架每月消耗大约10 MW-h的功率（包括冷却开销）。即使以每千瓦时15美分的高价（一半为实际功率，一半为分摊不间断电源[UPS]和配电设备），每月的电力和冷却成本也仅为1,500美元。与每月7,700美元的折旧费用相比，这样的费用很小。 因此，低功耗服务器不得比常规服务器贵，这样才能在我们的设置中具有总体成本优势。

## 硬件级应用程序特征

检查应用程序的各种体系结构特征有助于说明哪些硬件平台将为我们的查询服务系统提供最佳的性价比。我们将专注于索引服务器的特性，它是基础架构的组成部分，其价格/性能对整体价格/性能的影响最大。索引服务器中的主要活动包括对倒排索引中的压缩信息进行解码，并针对可能满足查询的一组文档查找匹配项。表1显示了在1-GHz双处理器Pentium III系统上运行的索引服务器程序的一些基本指令级度量。

考虑到奔腾III能够在每个周期发出3条指令，因此该应用程序具有较高的CPI。实际上，即使奔腾4可以同时发布更多指令并且具有出色的分支预测逻辑，但在更新的奔腾4处理器上运行的相同工作负载却具有接近两倍的CPI和近似相同的分支预测性能。 本质上，工作负载中没有太多可利用的指令级并行性（ILP）。 我们的测量结果表明，现代处理器中出现的无序，推测性执行水平已经超出了降低此类程序的性能回报的程度。

为诸如索引服务器之类的应用程序一种更有利可图的方法是可并行化计算。每个查询处理与系统的其余部分共享了大部分只读数据，并且构成了一个几乎不需要通信的工作单元。我们已经在集群级别通过部署大量廉价节点而不是更少的高端节点来利用这一优势。在微体系结构级别利用如此丰富的线程级别并行性似乎同样有希望。可用的线程级并行性应允许内核数量实现近乎线性的加速，并且合理大小的共享L2高速缓存将加速处理器之间的通信。

表1还概述了主要的内存系统性能参数。由于相对较小的内循环代码大小，我们观察到了指令高速缓存和指令转换后备缓冲区的良好性能。由于索引数据的绝对大小和索引数据块访问模式的不可预测性，索引数据块没有时间上的局部性。但是，索引数据块内的访问确实受益于空间局部性，硬件预取（或可能更大的缓存行）可以利用空间局部性。最终结果是，即使对于相对较小的缓存大小，总体缓存命中率也很高。





