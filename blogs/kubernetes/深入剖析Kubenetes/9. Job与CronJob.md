# 容器编排与Kubernetes作业管理

## 学习总结

K8S支持编排长期运行作业和执行完即退出的作业：

（1）支持Long Running Job（长期运行的作业）： Deployment 、StatefulSet、DaemonSet

（2）这次好Batch Job（执行完即退出的作业）：Job、CronJob

CronJob与Job关系，正如同Deployment与ReplicaSet的关系一样。CronJob是一个专门用来管理Job对象的控制器。只不过，它创建和删除Job的依据，是schedule字段定义的



## 22 撬动离线业务：Job与CronJob

Deployment、StatefulSet以及DaemonSet，它们主要编排的对象，都是“在线业务”，即：Long Running Task（长作业）。比如，我们在前面举例常用的Nginx、Tomcat以及MySQL等等。这些应用一旦运行起来，除非出错或者停止，它的容器进程会一直保持在Running状态。但是，有一类作业显然不满足这样的条件，这就是“离线业务”，或者叫做Batch Job（计算业务）。这种业务在计算完成后就直接退出了，而此时如果你依然用Deployment来管理这种业务的话，你就会发现Pod会在计算结束后退出，然后被Deployment Controller不断地重启；而像“滚动更新”这样的编排功能，更无从谈起了。

### 22.01 Job API对象

Job API对象的定义非常简单，如下所示：

```
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    spec:
      containers:
      - name: pi
        image: resouer/ubuntu-bc 
        command: ["sh", "-c", "echo 'scale=10000; 4*a(1)' | bc -l "]
      restartPolicy: Never
  backoffLimit: 4
```

从command看，这其实就是一个计算pi（圆周率）值的容器。通过scale=10000，指定了输出的小数点后的位数是10000。这个计算大概会耗时30秒。

跟其他控制器不同的是，Job对象并不要求你定义一个spec.selector来描述要控制哪些Pod，具体原因，后面介绍。

现在开始创建这个Job：

```
$ kubectl create -f job.yaml
```

在成功创建后，我们来查看一下这个Job对象，如下所示：

```
$ kubectl describe jobs/pi
Name:         pi-7rjg2
Namespace:    default
Priority:     0
Node:         bd011088191046.na610/11.88.191.46
Start Time:   Mon, 04 May 2020 20:37:11 +0800
Labels:       controller-uid=38398efa-ab75-4099-9607-82a30c8872f6
              job-name=pi
Annotations:  <none>
Status:       Running
IP:           10.36.0.4
IPs:
  IP:           10.36.0.4
Controlled By:  Job/pi
Containers:
  pi:
    Container ID:  docker://393b4f050a44e2c07fe51c86b712ffbe616cb1a24dc42b089b0152c9fdc0cac4
    Image:         resouer/ubuntu-bc
    Image ID:      docker-pullable://resouer/ubuntu-bc@sha256:3aff2cb1513375dc4ec42b80e8694cd1f9a8970fa5a55ebff98e1b85fe241d7f
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      echo 'scale=10000; 4*a(1)' | bc -l
    State:          Running
      Started:      Mon, 04 May 2020 20:37:19 +0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-zp682 (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  default-token-zp682:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-zp682
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age        From                           Message
  ----    ------     ----       ----                           -------
  Normal  Scheduled  <unknown>  default-scheduler              Successfully assigned default/pi-7rjg2 to bd011088191046.na610
  Normal  Pulling    27s        kubelet, bd011088191046.na610  Pulling image "resouer/ubuntu-bc"
  Normal  Pulled     20s        kubelet, bd011088191046.na610  Successfully pulled image "resouer/ubuntu-bc"
  Normal  Created    20s        kubelet, bd011088191046.na610  Created container pi
  Normal  Started    20s        kubelet, bd011088191046.na610  Started container pi

```

可以看到，这个Job对象在创建后，它的Pod模版，Label被自动加上了一个controller-uid=一个随机字符串。而这个Job对象本身，则被自动加上了这个label对应的Selector，从而保证了Job与它所管理的Pod之间的匹配关系。而Job Controller之所有要使用这种携带了UID的Label，就是为了避免不同Job对象所管理的Pod发生重合。需要注意的是，这种自动生成的Label对用户来说并不友好，所以不台适合推广到Deployment等长作业编排对象上。

接下来，可以看到这个Job创建的Pod进入了Running状态，这意味着它正在计算Pi的值

```
$ kubectl get pods
NAME                                READY     STATUS    RESTARTS   AGE
pi-rq5rl                            1/1       Running   0          10s

```

而几分钟后计算结束，这个Pod就会进入Completed状态：

```
$ kubectl get pods
NAME                                READY     STATUS      RESTARTS   AGE
pi-rq5rl                            0/1       Completed   0          4m
```

这也是我们需要在Pod模版中定义restartPolicy=Never的原因：离线计算的Pod永远都不应该被重启，否则它们会再重计算一遍。此时，我们通过Kubectl logs查看一下这个Pod的日记，就可以看到计算得到的Pi值已经被打印出来：

```
$ kubectl logs pi-rq5rl
3.141592653589793238462643383279...
```

这时候，你一定会想到这样一个问题，如果这个离线作业失败了要怎么办？

如果定义了restartPolicy=Never，那么离线作业失败后不会重启Pod里的容器，Job Controller会不断尝试创建一个新的Pod，当然，这个尝试肯定不会无限进行下去。所以，我们就在Job对象的spec.backoffLimit字段里定义了重试次数为4（即，backoffLimit=4），而这个字段的默认值是6。

而如果你定义的restartPolicy=OnFailure，那么离线作业失败后，Job Controller就不会去尝试创建新的Pod。但是，它会不断地尝试重启Pod里的容器。

如前所述，当一个Job的Pod运行结束后，它会进入Completed状态。但是，如果这个Pod因为某种原因一直不肯结束呢？

在Job的API 对象里，有一个spec.activeDeadlineSeconds字段可以设置最长运行时间，比如：

```
spec:
 backoffLimit: 5
 activeDeadlineSeconds: 100
```

一旦运行超过了100 s，这个Job的所有Pod都会被终止。并且，你可以在Pod的状态里看到终止的原因是reason: DeadlineExceeded。

### 21.02 Job Controller对并行作业的控制方法

在Job对象中，负责并行控制的参数有两个：
1.spec.parallelism，它定义的是一个Job在任意时间最多可以启动多少个Pod同时运行
2.spce.completions，它定义的是Job至少要完成的Pod数目，即Job的最小完成数

用如下例子进行说明：

```
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  parallelism: 2
  completions: 4
  template:
    spec:
      containers:
      - name: pi
        image: resouer/ubuntu-bc
        command: ["sh", "-c", "echo 'scale=5000; 4*a(1)' | bc -l "]
      restartPolicy: Never
  backoffLimit: 4
```

这样，我们就指定了这个Job最大的并行数是2，而最小的完成数是4。

执行后，可以看到，这个Job其实也维护了两个状态字段，即DESIRED和SUCCESSFUL，如下所示：

```
$ kubectl apply -f job.yaml
$ kubectl get job
NAME      DESIRED   SUCCESSFUL   AGE
pi        4         0            3s
```

然后，我们可以看到，这个Job首先创建了两个并行运行的Pod来计算Pi：

```
$ kubectl get pods
NAME       READY     STATUS    RESTARTS   AGE
pi-5mt88   1/1       Running   0          6s
pi-gmcq5   1/1       Running   0          6s
```

而在30s之后，这两个Pod相继完成计算。这时我们可以看到，每当有一个Pod完成计算进入Completed状态时，就会有一个新的Pod被自动创建出来，并且快速地从Pending状态进入到ContainerCreating状态。最终，后面创建的两个Pod也完成了计算，进入了Completed状态。这时，由于所有的Pod均已经成功退出，这个Job也就执行完了，所以你就看到它的SUCCESSFULE字段的值变成了4

```
$ kubectl get pods 
NAME       READY     STATUS      RESTARTS   AGE
pi-5mt88   0/1       Completed   0          5m
pi-62rbt   0/1       Completed   0          4m
pi-84ww8   0/1       Completed   0          4m
pi-gmcq5   0/1       Completed   0          5m

$ kubectl get job

```

### 22.03 CronJob API对象

顾名思义， CronJob描述的，正是定时任务。它的API对象，如下所示： 

```
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
```

在这个YAML文件里中，最重要的关键词就是jobTemplate。看到它，你一定恍然大悟，原来CronJob是一个Job对象的控制器。没错， CronJob与Job关系，正如同Deployment与ReplicaSet的关系一样。CronJob是一个专门用来管理Job对象的控制器。只不过，它创建和删除Job的依据，是schedule字段定义的，一个标准的Unix Cron格式的表达式。比如，
"*/1 * * * *"。这个Cron表达式里，\*/1表示从0开始，/表示“每”，1表示偏移量。所以，它的意思就是：从0开始，每1个时间单位执行一次。Cron表达式中的五个部分分别代表：分钟、小时、日、月、星期。所以，上面这句Cron表达式的意思是：从当前开始，每分钟执行一次。而这里要执行的内容，就是jobTemplate定义的Job了。

所以，这个CronJob对象在创建1分钟后，就会有一个Job产生了，如下所示：

```
$ kubectl create -f ./cronjob.yaml
cronjob "hello" created

$kubectl get job
NAME               COMPLETIONS   DURATION   AGE
hello-1588597020   1/1           6s         65s
hello-1588597080   0/1           5s         5s
```

需要注意的是，由于定时任务的特殊性，很可能某个Job还没有执行完，另一个新的Job就产生了。这时候，你可以通过spec.concurrencyPolicy字段来定义具体的处理策略，比如：

1: concurrencyPolicy=Allow，这也是默认情况，这意味着这些Job可以同时存在；
2: concurrencyPolicy=Forbid，这意味着不会创建新的Pod，该创建周期被跳过
3: concurrencyPolicy=Replace，这意味着新产生的Job会替换旧的，没有执行完的Job

而如果某一个Job创建失败，这次创建就会被标记为"miss"。当在指定的时间窗口内，miss的数目达到100时，那么CronJob会停止再创建这个Job。这个时间窗口，可以由spec.startingDeadlineSeconds字段指定。默认为100。







