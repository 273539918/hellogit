## 52. 答疑文章



## 问题1:  修复容器中的top命令

问题1:  你是否知道如何修复容器中的top指令以及/proc文件系统中的信息呢？

问题回溯： Cgroups对资源的限制能力也有很多不完善的地方，比如/proc文件系统的问题。当使用top命令查看进程的信息，比如CPU使用情况、内存占用率等，由于top也访问/proc文件来获得这些信息，因此在容器中执行top显示的是宿主机的CPU和内存数据，而不是当前容器的数据。造成这个问题的原因就是，/proc文件系统并不知道用户通过Cgroups给这个容器做了什么样的资源限制，即： /proc文件系统不了解Cgruops限制的存在。

来源：《白话容器基础（二）：隔离与限制》

答： 其实，这个问题的答案在提示里已经给出了，即lxcfs方案。通过lxcfs，你可以把宿主机的/var/lib/lxcfs/proc 文件系统挂在到Docker容器的/proc目录下。使得容器中进程读取到相应文件内容时，实际上会从容器对应的Cgroups中读取正确的资源限制。从而得到正确的top命令的返回值

> lxcfs 是一个开源的FUSE（用户态文件系统），让容器内的应用在读取内存和CPU信息的时候通过lxcfs的映射，转到自己的cgroup中相关定义信息读取的数据上。



## 问题2: 镜像是如何修改只读方式的rootfs的？

问题2:  既然容器里的rootfs（比如，Ubuntu镜像），是以只读方式挂载的，那么又如何在容器里修改Ubuntu镜像的内容呢？

来源：《白话容器基础（三）：深入理解容器镜像》

答：简单地说，修改一个镜像里的文件的时候，联合文件系统首先会从上到下在各个层中查找有没有目标文件。如果找到，就把这个文件复制到可读写层进行修改。这个修改的结果会屏蔽掉下层的文件，这种方式就被称为copy-on-write。

>容器的rootfs由三部分组成：
>1: 只读层（ro+wh）: 对应的正式ubuntu:latest镜像的五层
>3: 可读写层（rw）:  用来存放你修改rootfs后产生的增量，无论是增、删、改、查都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用docker commit和push指令，保存这个被修改过的可读写层，并上传到Docker Hub上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这就是增量rootfs的好处 
>2: init层（ro+wh）: init层是docker项目单独生成的一个内部层，专门用来存放/etc/hosts、/etc/resolv.conf等信息，这些文件本来属于只读的Ubuntu镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如hostname，所以就需要在可读写层对它们进行修改，但是我们又不希望执行docker commit时，把这些信息连通可读写层一起提交掉。因此以一个单独的层挂载了出来
>
>最终，这7个层被联合挂载到了/var/lib/docker/aufs/mnt目录下



## 问题3

问题3: 你在查看Docker容器的Namespace时，是否注意有一个叫cgroup的Namesapce?它是Linux 4.6之后新增加的一个Namespace，你知道它的作用吗？

来源：《白话容器基础（四）：重新认识Docker容器》

答：Linux内核从4.6开始，支持了一个新的Namespace叫做：Cgroup Namesapce。我们知道，正常情况下，在一个容器里查看/proc/$PID/cgroup，是会看到整个宿主机的cgroup信息的。而有了Cgroup Namespace后，每个容器里的进程都会有自己Cgroup Namespace，从而获得一个属于自己的Cgroups文件目录视图。也就是说，Cgroups文件系统也可以被Namespace隔离起来了。

> 一个进程的每种Linux Namespace都在它对应的/proc/[进程号]/ns 下有一个对应的虚拟文件，并且链接到一个真实的Namespace文件上。有了这样一个可以“hold”住所有Linux Namespace的文件，我们就可以对Namespace做一些很有意义的事情了，比如：加入到一个已经存在的Namespace当中。



## 问题4 

问题4 你能否说出，Kubernetes使用的这个“控制器模式”，跟我们平时所说的“事件驱动”，有什么区别和联系

来源：《编排其实很简单：谈谈“控制器”模型》

答：这里"控制器模式"和“事件驱动”最关键的区别在于：

（1）对于控制器来说，被监听对象的变化是一个持续的信号，比如变成ADD状态。只要这个状态没变化，那么此后无论任何时候控制器再去查询对象的状态，都应该是ADD

（2）而对于事件驱动来说，它只会在ADD事件发生的时候发出一个事件。如果控制器错过了这个事件，那么它就有可能再也没办法知道ADD这个事件的发生了。



## 问题5 

问题5: 在实际场景中，有一些分布式应用的集群是这么工作的：当一个新节点加入到集群时，或者老节点被迁移后重建时，这个节点可以从主节点或者其他从节点那里同步到自己所需要的数据。在这种情况下，你认为是否还有必要将这个节点Pod与它的PV进行一对一绑定呢？（提示：这个问题的答案根据不同的项目是不同的。关键在于，重建后的节点进行数据恢复和同步的时候，是不是一定需要原先它写在本地磁盘里的数据）

问题来源：《深入理解StatefulSet（二）：存储状态》

答：答案是不需要。像这种不依赖PV保持存储状态或者不依赖于DNS名字保持拓扑状态的“非典型”应用的管理，都应该使用Operator来实现（Operator可以自定义实现从其他节点同步数据）。



## 问题7

问题7: 在Operator的实现过程中，我们再一次用到了CRD。可是，你一定要明白，CRD并不是万能的，它有很多场景不适用，还有性能瓶颈。你能列出一些不适用CRD的场景么？你知道造成CRD性能瓶颈的原因主要在哪里么？

问题来源：《聪明的微创新：Operator工作原理解读》

答：CRD目前不支持protobuf，当API Object数量>1k，或者单个对象 >1KB，或者高频请求时，CRD的响应都会有问题。所以，CRD千万不能也不应该被当作数据库使用。 其实像Kubernetes，或者说Etcd本身，最佳的使用场景就是作为配置管理的依赖。此外，如果业务需求不能使用CRD进行建模的时候，比如，需要等待API最终返回，或者需要检查API的返回值，也是不能用CRD的。同时，当你需要完成的APIServer而不是只关心API对象的时，请使用API Aggregator.

> CRD在ETCD里面是以JSON格式来存储的，而K8S的API对象是以protobuf格式存储，在资源对象数量多的时候JSON的序列化和反序列化性能会成为瓶颈。



## 问题8

问题8: 正是由于需要使用“延迟绑定”这个特性，Local Persistent Volume 目前还不能支持Dynamic Provisioning。你能否说出，为什么“延迟绑定”会跟Dynamic Provisioning有冲突

问题来源： 《PV、PVC体系是不是多次一举？从本地持久化卷谈起》

答：延迟绑定将Volume Bind的时机，推迟到了第一个使用该Volume的Pod到达调度器的时候。可是对于Dynamic Provisiong来说，它是要在管理Volume的控制循环里就为PVC创建PV然后绑定起来的，这个时间点跟Pod被调度的时间点是不相关的。



## 问题9

问题9: 请你根据编写FlexVolume和CSI插件的流程，分析一下上面时候该使用FlexVolume，什么时候该使用CSI ？

问题来源：《容器存储实践：CSI插件编写指南》

答： CSI和FlexVolume的最大区别，在于CSI可以使用Provision阶段。所以说，对于不需要Provision的情况，比如你的远程存储服务总是事先准备好或者准备起来非常简单的情况下，就可以考虑使用FlexVolume。但是在生产环境下，推荐使用CSI方案。

> 相比于 FlexVolume，CSI 的设计思想，把插件的职责从“两阶段处理”，扩展成了 Provision、Attach 和 Mount 三个阶段。其中，Provision 等价于“创建磁盘”，Attach 等价于“挂载磁盘到虚拟机”，Mount 等价于“将该磁盘格式化后，挂载在 Volume 的宿主机目录上”。



## 问题10

问题10:  Flannel 通过“隧道”机制，实现了容器之间三层网络（IP地址）的连通性。但是，根据这个机制的工作原理，你认为Flannel能保证容器二层网络（MAC地址）的连通性吗？为什么呢？

问题来源：《深入解析容器跨主机网络》

答： 不能保证，因为“隧道”机制只能保证被封装的IP包可以到达目的地。而只要网络插件能满足Kubernetes网络的三个假设，Kubernetes并不关心你的网络插件的实现方式是把容器二层连通的，还是三层连通的。

> Flannel的“隧道”机制，通过封包和解包实现了容器之间的三层（IP）连通，其本质还依赖宿主机网络的IP层转发到目的宿主机



## 问题11

问题11: 你能否总结一下三层网络方案和“隧道模式“的异同，以及各自的优缺点？

问题来源：《解读Kubernetes三层网络方案》

答： 隧道模式最大的特点，在于需要通过某种方式比入UDP或者VXLAN来对原始的容器间通信的网络包进行封装，然后伪装成宿主机间的网络通信来完成容器的跨主通信。这个过程就不可避免地需要封包和解封包。这两个操作的性能损耗都是非常明显的。而三层网络方案则避免了这个过程，所以性能会得到很大提升。

不过，隧道模式的优点在于，它依赖的底层原理非常直白，内核里的实现也非常成熟和稳定。而三层网络方案，相对来说维护成本会比较高，容易碰到路由规则分发和设置出现问题的情况，并且当容器数量很多时，宿主机上的路由规则会非常复杂，难以Debug。



## 问题12

问题12: 为什么宿主机进入MemoryPressure或者DiskPressure状态后，新的Pod就不会被调度到这台宿主机上呢？

问题来源：《Kubernetes的资源模型与资源管理》

答：在Kubernets里，实际上有一种叫作Taint Nodes by Condition的机制，即当Node本身进入异常状态的时候，比如Condition变成了DiskPressure。那么，Kubernetes会通过Controller自动给Node加上对应的Taint，从而阻止新的Pod调度到这台宿主机上。



## 问题13

问题13: Kubernetes默认调度器与Mesos的“两级”调度器，有什么异同呢？

问题来源：《十字路口上的Kubernetes默认调度器》

答： Mesos的两级调度器的设计，是Mesos着急充当0层调度器（Layer 0），负责统一管理整个集群的资源情况，把可用资源以Resource  Offer的方式暴露出去；而上层的大数据框架（比如Spark，Flink）则充当1层调度器（Layer 1），它会负责根据Layer 0发来的Resource Offer来决定把任务调度到某个具体的节点上。这样做的好处是：

1）上层大数据框架本身往往自己已经实现了调度逻辑，这样它就可以很方便地接入到Mesos里面

2）这样的设计，使得Mesos本身能够统一地对上层所有框架进行资源分配，资源利用率和调度效率就可以得到很好地保证了

相比之下，Kubernetes的默认调度器实际上无论从功能还是性能上都要简单很多。这也是为什么把Spark这样本身就具有调度能力的框架接入到Kubernetes里面还是比较困难的。



## 问题14

问题14: 当整个集群发生可能会影响调度结果的变化（比如，添加或者更新Node，添加和更新PV、Service）时，调度器会执行一个被称为MoveAllToActiveQueue的操作，把所有调度失败的Pod从unschedulabelQ移动到activeQ里面。请问这是为什么？

问题来源：《Kubernetes默认调度器的优先级与抢占机制》

答： 一个相似的问题是，当一个已经调度成功的Pod被更新时，调度器则会将unschedulableQ里所有跟这个Pod有Affinity/Anti-affinity关系的Pod，移动到activeQ里面。请问这是为什么呢？ 其实，这两个问题的答案是一样的。在正常情况下，默认调度器在调度失败后，就会把该Pod放到unschedulableQ里。unschedulableQ里的Pod是不会出现在下个调度周期里的。但是，当集群发生变化时，这个Pod就有可能再次变成可调度的了，所以这时候调度器要把它们移动到activeQ里面，这样它们就获得了下一次调度的机会。类似地，当原本已经调度成功的Pod被更新后，也有可能触发unschedulableQ里与它有Affinity或者Anti-Affinity关系的Pod变成可调度的，所以它也需要获得“重新做人”的机会

## 问题15

问题15: 请你思考一下，我前面讲解过的Device Plugin为容器分配的GPU信息，是通过CRI的哪个接口传递给dockershim，最后提交给Docker API的呢？

问题来源：《解读CRI与容器运行时》

答：既然GPU是Devices信息，那当然是通过CRI的CreateContainerRequest接口。这个接口参数ContainerConfig里就有容器Devices的描述。

> 当一个Pod想要使用一个GPU的时候，在Pod的limits字段声明想要的数量1。那么接下来，Kubernetes的调度器就会从它的缓存里，寻找GPU数量满足条件的Node，然后将缓存里的GPU数量减1，完成Pod与Node的绑定。
>
> 这个调度成功后的Pod信息，自然就会被对应的kubelet拿来进行容器操作。而当kubelet发现这个Pod的容器请求一个GPU的时候，kubelet就会从自己持有的GPU列表里，为这个容器分配一个GPU。此时，kubelet就会向本机的Device Plugin发起一个Allocate()请求。这个请求携带的参数，正是即将分配给该容器的设备ID列表。
>
> 当Device Plugin收到Allocated请求之后，它就会根据kubelet传递过来的设备ID，从Device Plugin里找到这些设备对应的设备路径和驱动目录。当然，这些信息，正是Device Plugin周期性的从本机查询到的。比如，在NVIDIA Device Plugin的实现里，它会定期访问nvidia-docker插件，从而获取到本机的GPU信息。
>
> 而被分配GPU对应的设备路径和驱动目录信息被返回给kubelet之后，kubelet就完成了为一个容器分配GPU的操作。接下来，kubelet会把这些信息追加在创建该容器所对应的CRI请求当中。这样，这个CRI请求发给Docker之后，Docker为你创建出来的容器里，就会出现这个GPU设备，并把它所需要的驱动目录挂在进行。
>
> 至此，Kubernetes为一个Pod分配一个GPU的流程就完成了。



## 问题16

问题16:安全容器的意义，绝不仅仅止于安全。你可以想象一下这样一个场景：比如，你的宿主机的Linux内核版本是3.6，但是应用却必须要求Linux内核版本是4.0。这时候，你就可以把这个应用运行在一个KataContainers里。那么请问，你觉得使用gVisor是否也能提供这种能力呢？原因是什么呢？

问题来源：《绝不仅仅是安全：Kata Containers与gVisor》

答： 答案是不能。gVisor的实现里并没有一个真正的Linux Guest Kernel在运行，它能支持的系统调用是有限的，只是 Linux 系统调用的一个子集。所以它不能像KataContainers或者虚拟机那样。实现容器和宿主机不同Kernel甚至不同操作系统的需求。

> 在性能上，KataContainers 和 KVM 实现的 gVisor 基本不分伯仲，在启动速度和占用资源上，基于用户态内核的 gVisor 还略胜一筹。但是，对于系统调用密集的应用，比如重 I/O 或者重网络的应用，gVisor 就会因为需要频繁拦截系统调用而出现性能急剧下降的情况。此外，gVisor 由于要自己使用 Sentry 去模拟一个 Linux 内核，所以它能支持的系统调用是有限的，只是 Linux 系统调用的一个子集。



## 问题17

问题17： 将日志直接输出到stdout和stderr，有没有其他的隐患或者问题呢？如何进行处理呢？

问题来源：《让日志无处可逃：容器日志收集与管理》

问题回溯： 当日志量很大的时候，直接将日志输出到容器 stdout 和 stderr 上，有没有什么隐患呢？有没有解决办法呢？

答： 这样做有一个问题，就是日志都需要经过Docker Daemon的处理才会写到宿主机磁盘上，所以宿主机没办法以容器为单位进行日志的Rotate。 





































