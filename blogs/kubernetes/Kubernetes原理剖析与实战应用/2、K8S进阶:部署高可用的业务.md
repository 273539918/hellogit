## 06 | 无状态应用：剖析 Kubernetes 业务副本及水平扩展底层原理

ReplicaController和RelicaSet都是Pod控制器，两者的定位完全相同。目前ReplicaSet已经完全替换掉了ReplicaController，ReplicaSet支持更强大的标签选择器，目前支持三种操作符：in、notin和exists。

一般我们不会单独使用ReplicaSet，而是使用更高级的Deployment，用Deployment来支持ReplicaSet自动滚动升级的场景。

例：deploy-demo.yaml

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment-demo
  namespace: demo
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
        version: v1
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

注意，`spec.selector.matchLabels`中写的 label 一定要能匹配得了`spec.template.metadata.labels`中的 label。

创建完成后，可以查看自动创建出来的rs

```
$kubectl create ns demo
kubectl apply -f deploy-demo.yaml
$kubectl get rs -n demo
NAME                               DESIRED   CURRENT   READY   AGE
nginx-deployment-demo-5d65f98bd9   3         3         3       14h
```

查看对应的pod是否运行成功

```
$kubectl get pod -n demo -l app=nginx,version=v1
NAME                                     READY   STATUS    RESTARTS   AGE
nginx-deployment-demo-5d65f98bd9-4kbkx   1/1     Running   0          14h
nginx-deployment-demo-5d65f98bd9-jvpdt   1/1     Running   0          14h
nginx-deployment-demo-5d65f98bd9-khqmd   1/1     Running   0          14h
```

然后，我们修改deploy-demo.yaml，更改`spec.template.metadata.labels`中的`version=v1`为`version=v2`，同时更新镜像`nginx:1.14.2`为`nginx:1.19.2`。

```
$ kubectl apply -f deploy-demo.yaml
Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
deployment.apps/nginx-deployment-demo configured
```

查看rs的变化

```
$ kubectl get rs -n demo
NAME                               DESIRED   CURRENT   READY   AGE
nginx-deployment-demo-5d65f98bd9   3         3         3       4m10s
nginx-deployment-demo-7594578db7   1         1         0       3s
```

查看pod的变化

```
$ kubectl get pod -n demo -l app=nginx -w
```



## 07 | 有状态应用：Kubernetes 如何通过 StatefulSet 支持有状态应用？

statefulset前置依赖service，如下：

statefulset-demo.yaml

```
apiVersion: v1
kind: Service
metadata:
  name: nginx-demo
  namespace: demo
  labels:
    app: nginx
spec:
  clusterIP: None
  ports:
  - port: 80
    name: web
  selector:
    app: nginx
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web-demo
  namespace: demo
spec:
  serviceName: "nginx-demo"
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.19.2-alpine
        ports:
        - containerPort: 80
          name: web
$kubectl apply -f statefulset-demo.yaml
$kubectl get sts -n demo
```

通过如下命令可以查看某一个namespace下的事件

```
$kubectl get event -n demo -w
LAST SEEN   TYPE     REASON             OBJECT                 MESSAGE
0s          Normal   SuccessfulCreate   statefulset/web-demo   create Pod web-demo-2 in StatefulSet web-demo successful
<unknown>   Normal   Scheduled          pod/web-demo-2         Successfully assigned demo/web-demo-2 to bd011088191046.na610
0s          Normal   Pulling            pod/web-demo-2         Pulling image "nginx:1.19.2-alpine"
0s          Normal   Pulled             pod/web-demo-2         Successfully pulled image "nginx:1.19.2-alpine"
0s          Normal   Created            pod/web-demo-2         Created container nginx
0s          Normal   Started            pod/web-demo-2         Started container nginx
0s          Normal   SuccessfulCreate   statefulset/web-demo   create Pod web-demo-3 in StatefulSet web-demo successful
<unknown>   Normal   Scheduled          pod/web-demo-3         Successfully assigned demo/web-demo-3 to bd011088191030.na610
```

```
$for i in 0 1 2;do kubectl exec web-demo-$i -n demo -- sh -c 'hostname';done;
web-demo-0
web-demo-1
web-demo-2
```

StatefuleSet根据spec.serviceName这个字段，为一个Pod创建了一个DNS记录，这个记录为 $(podname).(headless service name)

接下来我们创建一个测试用的容器，来验证Pod的DNS记录

```
$kubectl run -it --rm --image busybox:1.28 test -n demo
If you don't see a command prompt, try pressing enter.
/ # nslookup web-demo-0.nginx-demo
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-demo-0.nginx-demo
Address 1: 10.44.0.2 web-demo-0.nginx-demo.demo.svc.cluster.local
/ # nslookup web-demo-1.nginx-demo
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-demo-1.nginx-demo
Address 1: 10.39.0.1 web-demo-1.nginx-demo.demo.svc.cluster.local
```

## **08 | 配置管理：Kubernetes 管理业务配置方式有哪些？**

不可变的配置是可以直接打包到镜像里的，那么可变的配置文件应该如何传入呢？

Kuberentes中用来存储可变配置的方式一般有：ConfigMap（非敏感数据）、Secret（敏感数据）

configmap的一个例子如下：

```
$ cat cm-demo-mix.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-demo-mix # 对象名字
  namespace: demo # 所在的命名空间
data: # 这是跟其他对象不太一样的地方，其他对象这里都是spec
  # 每一个键都映射到一个简单的值
  player_initial_lives: "3" # 注意这里的值如果数字的话，必须用字符串来表示
  ui_properties_file_name: "user-interface.properties"
  # 也可以来保存多行的文本
  game.properties: |
    enemy.types=aliens,monsters
    player.maximum-lives=5
  user-interface.properties: |
    color.good=purple
    color.bad=yellow
    allow.textmode=true
```

Pod要使用的configmap，必须和pod所在的namespace相同，下面用例子说明configmap在pod中的3种使用方式：

（1）读取部分变量作为命令行参数

（2）通过环境变量，注入部分或全部变量

（3）挂载文件，可以是单个文件，也可以是所有键值对，用每个键值作为文件名。

例： 

```
$ cat cm-demo-pod.yaml
apiVersion: v1
kind: Pod
metadata:
    name: cm-demo-pod
    namespace: demo
spec:
    containers:
        - name: demo
          image: busybox:1.28
          command:
              - "bin/sh"
              - "-c"
              - "echo PLAYER_INITIAL_LIVES=$PLAYER_INITIAL_LIVES && sleep 10000"
          env:
            # 定义环境变量
              - name: PLAYER_INITIAL_LIVES
                valueFrom:
                    configMapKeyRef:
                        name: cm-demo-mix  # 这个值来自ConfigMap
                        key: player_initial_lives # 需要取值的键
              - name: UI_PROPERTIES_FILE_NAME
                valueFrom:
                    configMapKeyRef:
                        name: cm-demo-mix
                        key: ui_properties_file_name
          #envFrom: # 可以将configmap中的所有键值都通过环境变量的注入容器中
          #    - configMapRef:
          #        name: cm-demo-mix
          volumeMounts:
          - name: full-config # 这里是下面定义的volume名字
            mountPath: "/config"  #挂载的目标路径
            readOnly: true
          - name: part-config
            mountPath: "/etc/game/"
            readOnly: true
    volumes: ## 可以在pod级别设置卷，然后将其挂载到Pod内的容器中
        - name: full-config ## 这里是volum的名字
          configMap:
            name: cm-demo-mix ## 提供你想要挂载的ConfigMap的名字
        - name: part-config
          configMap:
            name: cm-demo-mix
            items: ## 只挂载部分的配置
            - key: game.properties
              path: properties
```

创建后可通过如下命令查看具体的config 

```
$kubectl exec -it cm-demo-pod -n demo sh
/ # env
KUBERNETES_SERVICE_PORT=443
KUBERNETES_PORT=tcp://10.96.0.1:443
UI_PROPERTIES_FILE_NAME=user-interface.properties
HOSTNAME=cm-demo-pod
SHLVL=1
HOME=/root
game.properties=enemy.types=aliens,monsters
player.maximum-lives=5

user-interface.properties=color.good=purple
color.bad=yellow
allow.textmode=true

TERM=xterm
KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
KUBERNETES_PORT_443_TCP_PORT=443
ui_properties_file_name=user-interface.properties
KUBERNETES_PORT_443_TCP_PROTO=tcp
player_initial_lives=3
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
PLAYER_INITIAL_LIVES=3
KUBERNETES_SERVICE_HOST=10.96.0.1
PWD=/

# ls /config
game.properties            player_initial_lives       ui_properties_file_name    user-interface.properties

# ls -alh
total 12
drwxrwxrwx    3 root     root        4.0K Dec 16 06:42 .
drwxr-xr-x    1 root     root        4.0K Dec 16 09:29 ..
drwxr-xr-x    2 root     root        4.0K Dec 16 06:42 ..2020_12_16_06_42_39.349637514
lrwxrwxrwx    1 root     root          31 Dec 16 06:42 ..data -> ..2020_12_16_06_42_39.349637514
lrwxrwxrwx    1 root     root          22 Dec 16 06:42 game.properties -> ..data/game.properties
lrwxrwxrwx    1 root     root          27 Dec 16 06:42 player_initial_lives -> ..data/player_initial_lives
lrwxrwxrwx    1 root     root          30 Dec 16 06:42 ui_properties_file_name -> ..data/ui_properties_file_name
lrwxrwxrwx    1 root     root          32 Dec 16 06:42 user-interface.properties -> ..data/user-interface.properties

# cat /etc/game/properties
enemy.types=aliens,monsters
```

可以看到，环境变量都已经正确注入，对应的文件和目录也都挂载进来了。
在上面ls -alh /config/后，我们看到挂载的文件中存在软链接，都指向了..data目录下的文件。这样做的好处，是 kubelet 会定期同步检查已经挂载的 ConfigMap 是否是最新的，如果更新了，就是创建一个新的文件夹存放最新的内容，并同步修改..data指向的软链接。

一般我们只把一些非敏感的数据保存到 ConfigMap 中，敏感的数据就要保存到 Secret 中了



### 09 | 存储类型：如何挑选合适的存储插件？

Kubernetes中的Volume设计和Docker的区别： Kubernetes的Volume生命周期与Pod相同，Docker的Volume与容器相同。

Kuberentes提供了如下常见的Volume plugin：
![Drawing 2.png](https://s0.lgstatic.com/i/image/M00/55/1E/Ciqc1F9pyiKAUanvAACt-6jm3jw792.png)

Kubelet 内部调用相应的 plugin 实现，将外部的存储挂载到 Pod 内。像临时存储和本地存储，Kuberentes均可内置使用，但是对于一些云厂商和第三方的插件，社区已经不推荐继续使用内置的方式了，而是推荐你通过 CSI（Container Storage Interface，容器存储接口）来使用这些插件。

为什么出现CSI ?  各种各样的第三方存储插件与k8s耦合在一起，难以维护和扩展。通过CSI来进行解耦





DownloadAPI使用示例：

```
$cat downloadapi-volume-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: kubernetes-downwardapi-volume-example
  labels:
    zone: us-est-coast
    cluster: test-cluster1
    rack: rack-22
  annotations:
    build: two
    builder: john-doe
spec:
  containers:
    - name: client-container
      image: busybox:1.28
      command: ["sh", "-c"]
      args:
      - while true; do
          if [[ -e /etc/podinfo/labels ]]; then
            echo -en '\n\n'; cat /etc/podinfo/labels; fi;
          if [[ -e /etc/podinfo/annotations ]]; then
            echo -en '\n\n'; cat /etc/podinfo/annotations; fi;
          sleep 5;
        done;
      volumeMounts:
        - name: podinfo
          mountPath: /etc/podinfo
  volumes:
    - name: podinfo
      downwardAPI:
        items:
          - path: "labels"
            fieldRef:
              fieldPath: metadata.labels
          - path: "annotations"
            fieldRef:
              fieldPath: metadata.annotations
```

查看container输出 

```
$kubectl logs kubernetes-downwardapi-volume-example\
...
cluster="test-cluster1"
rack="rack-22"
zone="us-est-coast"

build="two"
builder="john-doe"
...
$kubectl exec -it kubernetes-downwardapi-volume-example -- sh
/ # ls /etc/podinfo/
annotations  labels

```

HostPath使用示例：

```
apiVersion: v1
kind: Pod
metadata:
  name: test-pd
  namespace: demo
spec:
  containers:
  - image: busybox:1.28
    name: test-container
    command: ["sh", "-c"]
    args:
    - while true; do
        sleep 10;
      done;
    volumeMounts:
    - mountPath: /test-pd
      name: test-volume
  volumes:
  - name: test-volume
    hostPath:
      # directory location on host
      path: /data
      # this field is optional
      type: Directory
```



### 10 | 存储管理：怎样对业务数据进行持久化存储？

volume和PV的区别：
1） 复用：PV可以复用数据，不会随着Pod的删除而删除，Pod重新调度后即可复用
2） 共享：Volume生命周期与Pod绑定，不同Pod共享volume会导致很多问题，而PV可以。  
3） 额外的属性和功能扩展： 比如，PV还可以控制挂载到该目录的Pod数量。而Volume层次就不好做多Pod之间的控制了

通过PV，存储也和Pod的生命周期解耦了

hostPath类型的Volume和Local host PV是什么区别：

 1） PV的话有最基本的IO隔离，一个PV一个盘 
 2)    PV可以控制挂载到该目录的Pod数量

例：

pv-demo.yaml

```
apiVersion: v1
kind: PersistentVolume
metadata:
  name: task-pv-volume # pv 的名字
  labels: # pv 的一些label
    type: local
spec:
  storageClassName: manual
  capacity: # 该 pv 的容量
    storage: 10Gi
  accessModes: # 该 pv 的接入模式
    - ReadWriteOnce
  hostPath: # 该 pv 使用的 hostpath 类型，还支持通过 CSI 接入其他 plugin
    path: "/mnt/data"
```

注意PV不归属某个namespace 

pvc-demo.yaml

```
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: task-pv-claim
  namespace: demo
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi
```

pvc-pod.yaml

```
apiVersion: v1
kind: Pod
metadata:
  name: task-pv-pod
  namespace: demo
spec:
  volumes:
    - name: task-pv-storage
      persistentVolumeClaim:
        claimName: task-pv-claim
  containers:
    - name: task-pv-container
      image: nginx:1.14.2
      ports:
        - containerPort: 80
          name: "http-server"
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: task-pv-storage
```

```
#kubectl exec -it task-pv-pod -n demo -- sh
#df -h
Filesystem      Size  Used Avail Use% Mounted on
overlay         237G   19G  206G   9% /
tmpfs            64M     0   64M   0% /dev
tmpfs           252G     0  252G   0% /sys/fs/cgroup
/dev/vda1       237G   19G  206G   9% /etc/hosts
shm              64M     0   64M   0% /dev/shm
tmpfs           252G   12K  252G   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs           252G     0  252G   0% /proc/acpi
tmpfs           252G     0  252G   0% /proc/scsi
tmpfs           252G     0  252G   0% /sys/firmware
# ls /usr/share/nginx/html
# touch /usr/share/nginx/html/test
## 宿主机上
#ls /mnt/data
test
```

### 11 | K8s Service：轻松搞定服务发现和负载均衡

Kuberentes中的Service一共有四种类型： ClusterIP、NodePort、LoadBalance、ExternalName
ClusterIP：相当于给Service选择的Pod挂上了一个VIP，在Kuberentes内可以通过访问这个VIP来访问到对应的Pod服务
NodePort：NodePort 类型的 Service 创建好了以后，Kubernetes 会在每个 Node 节点上开个端口。通过 Node+Port -> 访问对应的Service -> 访问Service对应的服务（Pod）
LoadBalance：需要与外部的云厂商适配，LoadBalancer主要用于做外部的服务发现，即暴露给集群外部的访问。
ExternalName:  使用场景，比如集群内部已经有一个服务（有域名），但是没有上到Kuberentes里面。Pod想要访问这个域名的话，这时当然可以直接使用它的域名地址，也可以通过 ExternalName 类型的 Service 来解决

Kubernetes集群内部访问Service的两种方式：
1）Service如果有ClusterIP，就直接通过ClusterIP来访问
2）通过域名来访问，如果是同namespace的pod，可以通过域名： <service_name>访问。如果是不同namespace的pod要访问，可以通过域名<service_name>.<namespace>

HeaderLess Service与普通Service的区别：
1） 没有ClusterIP 2) DNS解析出来的一个跟ClusterIP相关，一个跟Pod的IP相关
HeaderLess Service的主要作用：
1）用户通过DNS解析出Pod地址后，自己选择用哪个Pod。 2）用户为Pod维护一个不变的DNS记录：<PodName>.<ServiceName>.<NamespaceName>.svc.cluster.local



### 12 | Helm Charts：如何在生产环境中释放部署生产力？

Helm对kubernetes的作用，就好比 npm对node.js的作用。避免我们在生产部署中编写复杂的yaml文件。

Helm的核心概念：
1、Chart： 可以理解成应用的安装包，通常包含了一组我们在 Kubernetes 要部署的 YAML 文件
2、Release：可以将 Release 理解成是 Chart 包部署后的一个 Chart（应用）实例
3、Config：让 Chart 实现参数可配置，即 Config。每个 Chart 包内还有一个 values.yaml 文件，用来记录可配置的参数和其默认值，在每个 Release 中，我们也可以指定自己的 values.yaml 文件用来覆盖默认的配置。

可以看到官网的定义：

> Helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources.

即： Helm是管理Charts的工具，Charts是Kubernetes资源预配置的软件包

例：

```
### 通过helm创建一个chart模版
$ helm create hello-world
Creating hello-world
$ tree ./hello-world
./hello-world
├── Chart.yaml
├── charts
├── templates
│   ├── NOTES.txt
│   ├── _helpers.tpl
│   ├── deployment.yaml
│   ├── hpa.yaml
│   ├── ingress.yaml
│   ├── service.yaml
│   ├── serviceaccount.yaml
│   └── tests
│       └── test-connection.yaml
└── values.yaml
3 directories, 10 files

```

创建的chart模版会自动创建
1、Chart.yaml：版本，annotation 等信息
2、charts目录：放置子Chart，可以是tar包
3、templates目录：放置模版文件，会根据values.yaml文件的内容来渲染成最终文件
4、values.yaml：可配置的参数和其默认值

```
### 自定义一个myvalues.yaml，用来替换values.yaml ，
$helm install -f myvalues.yaml hello-world ./hello-world
```



























