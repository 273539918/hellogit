The anatomy of a large-scale hypertextual Web search engine

https://blog.csdn.net/fover717/article/details/8081131
https://www.zhihu.com/question/19937854


0. 概述

在本文中，我们介绍Google ，Google是一个大型搜索引擎原型，它大量使用了超文本中的结构信息。Google旨在有效地在Web上抓取和建立索引，并产生
更令人满意的搜索结果。本文对Google的大型网络搜索引擎进行了深入的描述。有两个挑战： 1. 传统的搜索技术如何应对日益增常的大规模数据
2. 如何利用超文本中的附加信息来产生更好的搜索结果。

1. 介绍

网络为信息检索带来了新的挑战。网络上的信息量和用户数量正在快速增长。我们已经建立了一个大规模的搜索引擎，解决了现有系统的许多问题。
该系统大量地使用超文本中存在的附加结构来提供更高质量的搜索结果。该系统叫做Google，它与单词google同义，google在数据上表示10的100次幂，
表示极大的数据，这很契合我们构建超大规模搜索引擎的目标。

搜索引擎技术必须快速发展才能跟上网络的发展速度。构建搜索引擎适应大规模的数据有很多挑战。 比如，需要快速爬虫技术来抓取网页并持续更新；
需要有效地使用存储空间来存储索引和优化后的文档；索引系统必须有效地处理大量数据；查询请求必须被快速地处理等等


2. 系统特点

谷歌搜索引擎有两个重要的特点，使得它能搜索出更精确的结果。首先，它利用网页中的链接结构来计算每个网页的质量排名，该排名被称为PageRank。其次，
Google 利用链接来优化搜索的结果。

2.1 网页排名的介绍
假设有一个页面A，指向它的有T1..TN。参数d是阻尼系数，值在0和1之间。通常我们将d设置为0.85。关于参数d会在下一章节详情介绍。C(A）表示A页面会
跳转到其他页面的超链接数量。网页排名的公式给出如下：

 PR(A) = (1-d) + d( PR(T1)/C(T1) +....+ PR(Tn)/C(Tn)  )

注意，所有的PageRank在各网页中形成概率分布，所以所有网页的PageRank的和会是1.

2.2 其他特性
 能够充分利用匹配项的位置信息
 google会跟踪一些视觉信息的细节，比如字体的颜色、大小d等。越大的字体拥有越高的权重

3. 网页与受控集合之间的差异

Web是一个庞大的完全不受控制的异构文档集合。网页上的文档与传统普通文档有很大的不同，比如，文档内部的语言（人工和编程），
所用的词汇（电子邮件地址，链接，邮政编码，电话号码，产品编号），文档的类型或格式（文本，HTML，PDF，图像，声音），文档甚至可能
是机器生成的，比如日志文件或数据库输出。还有外部元信息比如来源的可行度、更新的频率、质量、流行度或使用率、引用等等。

网页上的文档与传统普通文档之间的另一个重要区别是几乎无法控制人们把什么文档上传到网络上。公司可以利用这种灵活性，操作搜索引擎的搜索结果以牟利
，这已成为一个严重的问题，这个问题在传统的封闭信息检索系统中尚未解决。

4. 系统解析

我们先高度抽象地讨论架构；然后，深入描述比较重要的数据结构；最后，对抓取、索引、搜索等主要工作做深入的分析。

4.1 Google架构概述

本节主要介绍整个系统的工作流程，如图1所示

1. "URL Server" 发送url列表给 "Crawler"
2. "Crawler"抓取网页后存储到 "Store Server"
3."Store Server"将网页压缩后存储到 "Repository",每一篇网页都有唯一一个与之相关联的ID号，称作docID，
每当有一个新的URL被分析出来的时候都会被赋予一个docID。
4. "indexer"从"Repository"中读取、解压并解析文档，每一篇文档都被转化为词汇出现情况的集合，被称为hits。
hits记录了词汇、在文档中的位置、对字号的估计和大小写。hits被存储到"barrels"。
5. "indexer"还会解析每个网页中的所有链接，并将有关它们的重要信息存储在锚"Anchors"文件中， 该文件包含足够的信息来确定每个链接源和目标。
以及链接的文本。
6. "URLResolver"读取"Anchors"并将相对URL转换为绝对URL，然后再转换为docID.每一个网页都有一个唯一的docID。同时生成"links"数据库，
存储docIDS对
7. "links"数据库用来对所有文档进行页面排名pagerank

最终的搜索结果由 pageranks, barrels 共同产生搜索结果

4.2  主要的数据结构

Google的数据结构已经过优化，因此可以以很少的成本对大型文档集进行爬取，建立索引和搜索。

4.2.a) Big Files
Big Files 是跨多个文件系统的虚拟文件，可通过64位整数寻址，而且在多个文件系统之间的分配是自动处理的，Big Files包还会处理文件描述符的分配
和释放，并支持可压缩的选项

4.2.b)Repository
Repository保存了所有网页的完整HTML，通过zlib压缩。在Repository中，文档一个接一个的存储，其结构如图2所示，以docID，长度和URL为前缀。


4.3  索引网络


- 解析： 任何旨在整个Web上运行的解析器都必须处理大量可能的错误。开发以合理的速度运行并且非常健壮的解析器需要大量的工作。
- 建立索引：每一个文档被解析后存入barrles。通过词典lexion（内存中的哈希表）将每一个单词被转换为一个word ID
- 排序：分类器根据word ID 产生倒序索引，分类器会将分类的结果再次写入barrles


5. 结果与性能

6. 结论


Google采用了多种技术来提高搜索质量，包括页面排名，锚文本和邻近信息。我们当前的目标是提高搜索效率，并将其扩展到大约1亿个网页。

